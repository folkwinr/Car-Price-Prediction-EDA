# ðŸ§ª Part-01 Methodology (Data Cleaning) â€” Step-by-Step (AutoScout24)

> In this part, our goal was: **raw JSON â†’ a clean, consistent, analysis/model-ready table**.  
> Our strategy was: **general cleaning + quality checks first**, then **column-by-column cleaning**, then **feature engineering**, and finally **final checks**.

---

## ðŸ§­ 0) Starting Logic: What problem are we solving?
Raw listing data usually has these issues:
- ðŸ§¾ messy column names / newline characters / special symbols (schema noise)
- ðŸ”¢ numeric values stored as **text** (price, mileage, consumption, powerâ€¦)
- ðŸ§© some cells are **lists** (equipment groups, some categorical fields)
- ðŸ•³ï¸ many missing values (especially WLTP / EV fields)
- ðŸ” possible duplicates (common in scraped data)

So our decision process was always:
- **First visibility:** â€œWhat do we have, how missing is it, what is the format?â€
- **Then cleaning:** â€œschema + noise removal + type conversionâ€
- **Then meaning:** â€œfeature engineering + category simplificationâ€
- **Finally checks:** â€œdata quality gatesâ€

---

## 1) ðŸ§° General Setup
### 1.1 ðŸ“¥ Load + Copy (Protect raw data)
- âœ… We loaded raw JSON using `pd.read_json(...)`.
- âœ… We created a copy: `df = df0.copy()`.
- **Why?** To keep the raw dataset safe and make it easy to compare changes.

### 1.2 ðŸ” Quick overview (skimpy + fast EDA tools)
- âœ… We used **skimpy** (and similar quick summaries) to see:
  - column types
  - missing rates
  - basic distribution signals
  quickly.
- âœ… We also used our helper functions (example: `first_looking`) to check per column:
  - missing percent / missing count
  - number of unique values
  - value_counts

**Main idea:**
> â€œSee the problem first. If you transform before understanding formats, parsing errors can grow.â€

---

## 2) ðŸ§¹ Global Cleaning Rules
### 2.1 ðŸ·ï¸ Column name standardization (Schema normalize)
- âœ… We used `to_snake_case()` to standardize column names:
  - remove newline characters / spaces / special symbols
  - lowercase + underscores
- **Why?** Safer code, better readability, better GitHub quality.

### 2.2 ðŸ—‘ï¸ Drop fully empty rows
- âœ… `dropna(how="all")`
- **Why?** Rows with no information only add noise.

### 2.3 ðŸ•³ï¸ Remove very empty columns (Missing threshold)
- âœ… We checked missing rates (`df_nans` / `show_missing_values`).
- âœ… Rule: **if a column has >80% missing values â†’ drop it**
- **Why?**
  - even in Part-02, there is not enough data to fill it well
  - these columns make the dataset bigger but not better

> Decision point:
> - If **>80% missing** â†’ **drop**
> - If medium missing â†’ keep and handle in **Part-02**
> - If a **core** column (price/mileage) â†’ keep and fill later

### 2.4 ðŸ” Duplicate check
- âœ… We tried `duplicated()` checks.
- ðŸ§© Because list-type columns can cause issues, we used a workaround like:
  - `df.astype(str).duplicated()` for a practical check
- **Why?** Scraped data can include repeated listings or near-repeats.

---

## 3) ðŸ§© Column-by-Column Cleaning Strategy
For each column we asked these 3 questions:

### âœ… Question-1: What is the column format?
- If it is a **list** â†’ list handling
- If it is **numeric-like text** â†’ regex + numeric conversion
- If it is **category/text** â†’ strip/normalize/mapping
- If it is **free text (desc)** â†’ drop in this phase (NLP not in scope)

### âœ… Question-2: Is this column useful?
- Is it a core feature? (price, mileage, age, power, fuelâ€¦)
- Is it too missing?
- Is it an ID / leakage risk? (Offer number)

### âœ… Question-3: Can we create a better feature from it?
- power â†’ kW + hp
- fuel_consumption â†’ avg/city/country
- first_registration â†’ age

---

## 4) ðŸ§· List Handling (Decision tree for list-type cells)
Some columns came as **lists**.

### 4.1 âœ… If the list is usually single-item (most common case)
- We used:
  - `x[0] if isinstance(x, list) else x`
- **Why?** It converts to a single value without changing row count.

### 4.2 âš ï¸ Where we used `.explode()` (practical but risky)
- For some columns we used: `explode().str.strip(...)`.
- **When is it OK?**
  - when we believe lists are almost always single-item
- **Risk:**
  - if a list has >1 item, `explode()` increases the number of rows â†’ dataset can break

> Strategy:
> - If we are â€œconfidentâ€ â†’ explode  
> - If we are â€œnot sureâ€ â†’ take the first element (safer)

### 4.3 ðŸ§© Equipment columns: list â†’ readable text
- For equipment groups (`comfort`, `entertainment`, `safety`, `extras`):
  - we used `", ".join(list)` to make one readable string
- **Why?** Part-01 aims for **readability + stable dataset**
- **Note:** For modeling later, better options are:
  - `equipment_count`
  - `has_feature_X` (0/1 flags)

---

## 5) ðŸ”¡ Regex for Numeric Conversion (Text â†’ Numeric Parsing)
This was the â€œcore engineâ€ of Part-01.

### 5.1 ðŸ’° Price
- We saw: values are text with currency and separators.
- We applied:
  - regex to extract the number (`extract`)
  - remove separators (like `,`)
  - convert to numeric (`astype(float)`)

**Why?** Without numeric price, EDA/outliers/models are not possible.

### 5.2 ðŸ›£ï¸ Mileage
- We saw: â€œkmâ€ text and separators.
- We applied:
  - separator cleanup
  - regex digit extraction
  - numeric conversion

### 5.3 âš™ï¸ Engine/weight/gear/cylinders-like fields
- We saw: numeric-like strings.
- We applied:
  - `extract('(\d+)')`
  - numeric conversion

> General rule:
> - if a number is inside text â†’ extract it â†’ convert to numeric  
> - if parsing is not safe â†’ treat it as missing and handle in Part-02

---

## 6) ðŸ§  Feature Engineering â€” â€œClean + Make it strongerâ€
This part was not only cleaning, but also making the data more useful.

### 6.1 ðŸ“… First registration â†’ Age
- We saw: registration format can be mixed, and **age** is easier for analysis.
- We applied:
  - extract year (often last 4 characters)
  - `age = reference_year - year`
- Then:
  - we dropped source columns like `first_registration` and `production_date` (redundant)

### 6.2 âš™ï¸ Power â†’ power_kW + power_hp
- We saw: power text often contains both kW and hp.
- We applied:
  - if list â†’ take first element
  - regex to extract two numbers
  - created two numeric columns
- Then:
  - dropped the source `power` column

### 6.3 â›½ Fuel consumption â†’ cons_avg / cons_city / cons_country
- We saw: consumption is a complex field in a single column.
- We applied:
  - helper functions to select correct parts
  - regex numeric extraction
  - created `cons_avg`, `cons_city`, `cons_country`
- Then:
  - dropped the source `fuel_consumption` column

---

## 7) ðŸ§© Categorical Normalization (Simplifying categories)
### 7.1 â›½ Fuel type mapping
- We saw: many different fuel labels.
- We applied:
  - split by `/` (take the first part)
  - mapping function to group similar labels
- **Why?** Too many categories makes analysis messy; fewer groups are clearer.

### 7.2 ðŸŒ¿ Emission / Efficiency grouping
- We saw: many variants in emission/efficiency labels.
- We applied:
  - functions that normalize/group values
- Decision:
  - some of these columns were later dropped (not needed for this phase)

---

## 8) ðŸ—‘ï¸ Drop Strategy (What we removed and why)
### 8.1 ðŸ§¾ Free text
- long text like `desc`:
  - dropped (NLP not included in this phase)

### 8.2 ðŸ†” ID / leakage
- `offer_number`:
  - dropped to avoid memorization/leakage in models

### 8.3 ðŸ•³ï¸ Very missing columns
- many WLTP/EV fields:
  - dropped by the >80% missing rule

### 8.4 ðŸ” Redundant after feature engineering
- `power` dropped after creating `power_kW/hp`
- `fuel_consumption` dropped after creating `cons_*`
- `first_registration` dropped after creating `age`

---

## 9) âœ… Data Quality Gates (Final checks)
At the end of Part-01 we checked:
- ðŸ§ª column dtypes (numeric fields are numeric)
- ðŸ•³ï¸ missing report (ready for Part-02)
- ðŸ” duplicate check output (drop decision can be applied later)
- ðŸ“Œ basic logic checks (negative values noted for Part-03 outlier handling)

---

## ðŸ Output: What we have after Part-01
- âœ… clean, standardized column names (snake_case)
- âœ… core numeric columns ready for analysis:
  - price, mileage, age, power_kW/hp, cons_*
- âœ… equipment columns made readable
- âœ… very missing / low-value / ID columns removed
- âœ… strong base for Part-02 (missing) and Part-03 (outliers)

---

## ðŸ”¥ Mini Decision Log (Short)
- **Missing >80%** â†’ drop  
- **List field** â†’ (if confident) explode, (if not) first element  
- **Text-number** â†’ regex extract + numeric conversion  
- **Better feature possible** â†’ create feature, then drop source column  
- **Free text / ID** â†’ drop (in this phase)
